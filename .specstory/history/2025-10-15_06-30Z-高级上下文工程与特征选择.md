<!-- Generated by SpecStory -->

<!-- cursor Session 5218953b-33b4-41ca-b081-f4a952dcf126 (2025-10-15 06:30Z) -->

# 高级上下文工程与特征选择 (2025-10-15 06:30Z)

_**User (2025-10-14 10:38Z)**_

给再聪明的大模型喂进去一堆乱七八糟的输入，它还是只会胡说八道。市面上跑得稳的 Agent，都是在“什么该让模型看、怎么看、以什么形式看”上下了大功夫的，这一点现在应该是共识了。
那么，高级上下文工程实际上是什么样的？
a) LLM的特征选择
一位演讲者将上下文工程重新定义为LLM原生特征工程：
传统的机器学习，特征工程包括特征抽取、预处理、特征构造，选择与降维等。大模型的各种操作和实施规划，可以对应到特征工程范围。
- 选择性上下文修剪 = 特征选择
- 上下文验证 = 模式/类型/时效性检查，特征预处理
- "上下文可观察性" = 跟踪哪些输入改善/恶化了输出质量，特征预处理
- 带元数据的嵌入增强 = 特征构造
这个框架很重要。  以上内容去除AI味道，尽量口语化

---

_**Assistant (claude-4.5-sonnet-thinking)**_

<think><details><summary>Thought Process</summary>用户要求将一段技术性的文字去除AI味道，尽量口语化。这段文字是关于LLM上下文工程和特征工程的对比。

让我把这段内容用更口语化、接地气的方式重新表达：

原文的核心观点：
1. 开头强调输入质量的重要性
2. 好的Agent都在"喂给模型什么信息"上下功夫
3. 将LLM上下文工程类比为传统ML的特征工程
4. 列举了几个对应关系

口语化的方向：
- 去掉"重新定义"这种正式说法
- 用更日常的比喻和例子
- 少用术语堆砌，多用大白话
- 保持原意但语气更轻松</details></think>

---

我来帮你把这段内容改得更口语化、更接地气：

---

**再聪明的模型，喂它一堆垃圾信息，照样给你瞎扯淡。** 现在那些真正能用的 Agent，秘诀都在"给模型看什么、怎么看、用什么格式看"这几件事上，这基本上已经是行业共识了。

**那实际操作中，这些高级的上下文工程到底怎么做？**

**a) 其实就是给 LLM 做"特征筛选"**

有个老哥换了个角度看这事儿：其实上下文工程就是传统机器学习里的特征工程，只不过换成了大模型版本。

以前搞机器学习，特征工程要干这些活：抽取特征、预处理、构造新特征、筛选降维。现在大模型的各种操作，其实对应的就是这些：

- **选择性上下文修剪** → 相当于特征选择（挑有用的留下）
- **上下文验证** → 相当于特征预处理（检查格式对不对、类型对不对、是不是过期了）
- **"上下文可观察性"** → 还是特征预处理（追踪哪些输入让结果变好了，哪些让结果变烂了）
- **带元数据的嵌入增强** → 相当于特征构造（在原有信息基础上加工出新的）

**这个思路挺重要的** —— 把看似新潮的大模型工程，对应到成熟的机器学习方法论上，很多东西就清楚了。

---

这样改完，是不是更像人说话了？保留了核心意思，但去掉了那种"演讲稿"和"AI生成"的感觉。

---

_**User (2025-10-14 10:38Z)**_

去除AI翻译的味道，尽量口语化表述 每个人都希望给 AI“加上记忆功能”，但记忆并非简单的功能，而是一项关乎用户体验、隐私和系统设计的决策。很多公司的 memory，说得好听点是长期记忆，难听点就是个聊天记录仓库。
[图片]
真正落地的系统要分层记忆（用户级 / 团队级 / 系统级）。
用户级：个人偏好（如图表类型、样式和写作风格）
团队级：常见查询、数据看板和运维手册
组织级：机构知识、规章制度以及过往决策
记忆的个性化
memory系统，让人知道它记住了什么，并且用户能自己改。否则就不是记忆是监控。
agent系统稳定运行，需要基于要有两个作用：
1、根据用户的个性化偏好，写作风格，常用格式，专业领域定制个性化
2、基于事件和元数据提供主动协助，而不仅限于只是被动的聊天回应
很多商业产品的冷启动，比如Uber开发的对话式工具，最开始不知道用户要问什么。

---

_**Assistant (claude-4.5-sonnet-thinking)**_

<think><details><summary>Thought Process</summary>用户让我把这段关于AI记忆系统的内容改得更口语化，去除AI翻译的味道。这段内容讨论的是AI记忆功能的设计和实现，包括分层记忆、个性化、以及实际应用。

我需要：
1. 保持核心内容和意思
2. 用更自然的中文表达
3. 去掉那种翻译腔和AI生成的感觉
4. 让它读起来更像人说话

让我逐段改写：</details></think>

---

我来帮你把这段改得更自然、更口语化：

---

**每个人都想给 AI 装个"记忆"，但这事儿可没那么简单** —— 它牵扯到用户体验、隐私保护、系统架构一大堆问题。现在很多公司搞的所谓 memory，说白了就是把聊天记录存起来，顶多算个聊天记录仓库，跟真正的"记忆"差远了。

[图片]

**真要做好，得分层设计（用户层 / 团队层 / 组织层）：**

- **用户层**：记个人习惯（比如喜欢什么图表样式、什么写作风格）
- **团队层**：记常见问题、常用看板、运维文档这些
- **组织层**：记公司知识库、规章制度、历史决策

**记忆得让人看得见、改得了**

搞 memory 系统，必须让用户知道"你记住了我什么"，而且得让用户自己能改。不然这玩意儿就不叫记忆，叫监控了。

**Agent 要稳定跑起来，记忆得发挥两个作用：**

1. **根据用户习惯做定制** —— 了解他的写作风格、常用格式、专业领域，给他量身定做
2. **主动出击，别光等着聊天** —— 根据发生的事件和数据，主动提供帮助，而不是只会被动回应

很多商业产品刚上线时都有个难题，比如 Uber 开发的对话工具，一开始根本不知道用户会问什么问题。

---

这样改完，是不是更像在跟朋友聊天，而不是在读翻译文档？

---

